{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tripadvisor  destination webscraper\n",
    "# author: Mohamed Wishan\n",
    "# date: 31.12.2020\n",
    "# Â© 2020 Mohamed Wishan, CC BY 4.0\n",
    "\n",
    "# install required libraries\n",
    "# intstall duplicated thrice to fix dependency errors\n",
    "!pip install mysql-connector-python\n",
    "!pip install requests-html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import time\n",
    "import datetime\n",
    "import mysql.connector\n",
    "from requests_html import HTMLSession\n",
    "from mysql.connector.constants import ClientFlag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up mysql SSL connection\n",
    "config = {\n",
    "    'user': 'yourusername',\n",
    "    'password': 'yourpassword',\n",
    "    'host': 'youripaddress',\n",
    "    'client_flags': [ClientFlag.SSL],\n",
    "    'ssl_ca': 'ssl/server-ca.pem',\n",
    "    'ssl_cert': 'ssl/client-cert.pem',\n",
    "    'ssl_key': 'ssl/client-key.pem'\n",
    "}\n",
    "try:\n",
    "    # add existing database to config dict\n",
    "    config['database'] = 'webscraper'\n",
    "    cnxn = mysql.connector.connect(**config)\n",
    "    cursor = cnxn.cursor()\n",
    "    print(\"Database connection successful\")\n",
    "except Exception as e:\n",
    "    print(\"Could not connect to the database\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # query a nonscraped destination to scrape\n",
    "    cursor.execute(\"SELECT * FROM destination WHERE destination_scraped=0 LIMIT 1\")\n",
    "    out2 = cursor.fetchall()\n",
    "    # print(out2[0][2])\n",
    "    if bool(out2):\n",
    "        url     = out2[0][2]\n",
    "        session = HTMLSession()\n",
    "        r       = session.get(url)\n",
    "    else:\n",
    "        print(\"No destination to scrape\")\n",
    "except Exception as e:\n",
    "    print(\"Could not run query\")\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for html in r.html:\n",
    "    time.sleep(3)\n",
    "    r = session.get(html.url)\n",
    "    r_hotel_name = r.html.find('.listing_title')\n",
    "    range_num = len(r_hotel_name)\n",
    "    hotel_list = []\n",
    "\n",
    "    for x in range(range_num):\n",
    "        # HOTEL NAME\n",
    "        if r_hotel_name[x].text[:9] == \"Sponsored\":\n",
    "          hotel_name = r_hotel_name[x].text[10:]\n",
    "        else: \n",
    "          hotel_name = r_hotel_name[x].text\n",
    "\n",
    "        destination_id = out2[0][0]\n",
    "        hotel_url = str(r_hotel_name[x].absolute_links)[2:-2]\n",
    "        last_updated  = datetime.datetime.now()\n",
    "        hotel_scraped = 0\n",
    "\n",
    "        hotel_tuple = (destination_id, hotel_name, hotel_url, last_updated, hotel_scraped)\n",
    "        hotel_list.append(hotel_tuple)\n",
    "    # END OF SCRAPING PAGE\n",
    "\n",
    "    # EXECUTE DATABASE CMD TO INSERT ALL HOTELS ON PAGE\n",
    "    try:\n",
    "        insert_hotel = (\"INSERT INTO hotel (destination_id, hotel_name, hotel_page_url, last_updated, hotel_scraped) \"\n",
    "        \"VALUES (%s, %s, %s, %s, %s )\")\n",
    "        cursor.executemany(insert_hotel, hotel_list)\n",
    "        cnxn.commit()\n",
    "        \n",
    "        print(\"DB INSERT SUCCESSFUL\")\n",
    "        print(r.html)\n",
    "    except Exception as e:\n",
    "        print(\"COULD NOT INSERT HOTELS TO DATABASE\")\n",
    "        print(\"URL:\")\n",
    "        print(r.html)\n",
    "        print(e)\n",
    "# END OF ALL PAGES\n",
    "\n",
    "try:\n",
    "    #EXECUTE FINAL DATABASE QUERY TO UPDATE THE DESTINATION AS FULLY SCRAPED\n",
    "    update_hotel = (\"UPDATE destination SET destination_scraped=1 WHERE id=%s\")\n",
    "    cursor.execute(update_hotel, (out2[0][0],))\n",
    "    cnxn.commit()\n",
    "    cnxn.close()\n",
    "    print(\"DESTINATION UPDATE SUCCESSFUL\")\n",
    "except Exception as e:\n",
    "    print(\"SQL ERROR: COULD NOT UPDATE DESTINATION AS SCRAPED\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    #EXECUTE FINAL DATABASE QUERY TO UPDATE THE DESTINATION AS FULLY SCRAPED\n",
    "    update_hotel = (\"UPDATE destination SET destination_scraped=1 WHERE id=%s\")\n",
    "    cursor.execute(update_hotel, (out2[0][0],))\n",
    "    cnxn.commit()\n",
    "    cnxn.close()\n",
    "    print(\"DESTINATION UPDATE SUCCESSFUL\")\n",
    "except Exception as e:\n",
    "    print(\"SQL ERROR: COULD NOT UPDATE DESTINATION AS SCRAPED\")\n",
    "    print(e)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}